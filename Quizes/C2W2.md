# Part of Speech Tagging

1. The Transition matrix A defined in lecture allows you to:
   - Compute the probability of going from a part of speech tag to another part of speech tag. 
2. The Emission matrix B defined in lecture allows you to:
   - Compute the probability of going from a part of speech tag to a word.
3. The column sum of the emission matrix has to be equal to 1.
   - False
4. The row sum of the transition matrix has to be 1.
   - True
5. Why is smoothing usually applied? Select all that apply.
   - Applying smoothing, for the majority of cases, allows us to decrease the probabilities in the transition and emission matrices and this allows us to have non zero probabilities.
   - Applying smoothing, for the minority of cases, allows us to increase the probabilities in the transition and emission matrices and this allows us to have non zero probabilities.
6. Given the following D matrix, what would be the sequence of tags for the words on the right?
   - $t_2,t_3,t_1,t_3,t_1$
7. Previously, we have been multiplying the raw probabilities, but in reality we take the log of those probabilities. Why might that be the case?
   - We take the log probabilities because probabilities are bounded between 0 and 1 and as a result, the numbers could be too small and will go towards 0.
8. Which of the following are useful for applications for parts of speech tagging?
   - Speech recognition
   - Named Entity Recognition
   - Coreference Resolution

## Viterbi Algorithm

```python
def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]
    path = {}
    
    # Initialize base cases (t == 0)
    for y in states:
        V[0][y] = start_p[y] * emit_p[y][obs[0]]
        path[y] = [y]
    
    # Run Viterbi for t > 0
    for t in range(1, len(obs)):
        V.append({})
        newpath = {}
        
        for y in states:
            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)
            V[t][y] = prob
            newpath[y] = path[state] + [y]
        
        # Don't need to remember the old paths
        path = newpath
    
    (prob, state) = max((V[len(obs) - 1][y], y) for y in states)
    return (prob, path[state])
```
