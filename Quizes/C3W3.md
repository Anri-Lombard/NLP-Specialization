# LSTMs and Named Entity Recognition

1. Identify the correct order of the gates that information flows through in an LSTM unit.
   - Forget gate, input gate, output gate.
2. Which are some applications of LSTMs?
   - all
3. The tanh layer ensures the values in your network stay numerically stable, by squeezing all values between -1 and 1.  This prevents any of the values from the current inputs from becoming so large that they make the other values insignificant.
    - True
4. What type of architecture is a named entity recognition using?
   - Many to many
5. Extract the named entities from the following sentence: Younes, a Moroccan artificial intelligence engineer, travelled to France for a conference.
   - Younes, Moroccan, France
6. In a vectorized representation of your data, equal sequence length allows more efficient batch processing.
   - True
7. Which built-in Python method would you use to iterate over your test set during the evaluation step? Assuming you are using a data generator.
    - next()
8. Why is it important to mask padded tokens when computing the loss?
   - Padded tokens are not part of the data and are just used to help us keep the same sequence length for more efficient batch processing. We should not include their loss.
9. In which of the following orders should we train an Named Entity Recognition with an LSTM?
   1. Create a tensor for each input and its corresponding number
   2. Put them in a batch =>  64, 128, 256, 512 ...
   3. Feed it into an LSTM unit
   4. Run the output through a dense layer
   5. Predict using a log softmax over K classes
10. LSTMS solve vanishing/exploding gradient problems when compared to basic RNNs.
    - True
